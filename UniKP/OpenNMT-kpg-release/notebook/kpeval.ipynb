{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import re\n",
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from collections import defaultdict\n",
    "\n",
    "module_path = os.path.abspath(os.path.join('..'))\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)\n",
    "module_path = os.path.abspath(os.path.join('../onmt'))\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)\n",
    "\n",
    "import kp_evaluate\n",
    "import onmt.keyphrase.utils as utils\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy\n",
    "\n",
    "from nltk.stem.porter import PorterStemmer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "kp20k_valid2k\n"
     ]
    }
   ],
   "source": [
    "dataset_names = ['kp20k_valid2k']\n",
    "# dataset_names = ['inspec', 'krapivin', 'nus', 'semeval', 'kp20k', 'duc', 'magkp', 'stackexchange']\n",
    "\n",
    "# json_base_dir = '/Users/memray/project/kp/OpenNMT-kpg/data/keyphrase/json/' # path to the json folder\n",
    "json_base_dir = '/zfs1/hdaqing/rum20/kp/data/kp/json' # path on CRC\n",
    "\n",
    "dataset_examples = {}\n",
    "    \n",
    "for dataset_name in dataset_names:\n",
    "    dataset_examples[dataset_name] = []\n",
    "    print(dataset_name)\n",
    "\n",
    "    input_json_path = os.path.join(json_base_dir, dataset_name, 'test.json')\n",
    "    \n",
    "    with open(input_json_path, 'r') as input_json:\n",
    "        for json_line in input_json:\n",
    "            ex_dict = json.loads(json_line)\n",
    "\n",
    "            if dataset_name == 'stackexchange':\n",
    "                ex_dict['abstract'] = ex_dict['question']\n",
    "                ex_dict['keywords'] = ex_dict['tags']            \n",
    "                del ex_dict['question']\n",
    "                del ex_dict['tags']\n",
    "\n",
    "            keywords = ex_dict['keywords']\n",
    "            ex_dict['fulltext'] = ''\n",
    "\n",
    "            if isinstance(keywords, str):\n",
    "                keywords = keywords.split(';')\n",
    "                ex_dict['keywords'] = keywords\n",
    "            keywords = [k.strip() for k in keywords]\n",
    "            ex_dict['keywords'] = keywords\n",
    "            \n",
    "            dataset_examples[dataset_name].append(ex_dict)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bart-o2s\n",
      "tf-o2s\n",
      "bart-o2o\n"
     ]
    }
   ],
   "source": [
    "pred_paths = {\n",
    "    'bart-o2s': '/zfs1/hdaqing/rum20/kp/fairseq-kpg/exps/kp/bartFT_presabs_kp20k_100k_rerun/outputs/beamsearch-width_50-maxlen_40/pred/checkpoint_step_45000-data_kp20k_valid2k_test.pred',\n",
    "    'tf-o2s': '/zfs1/hdaqing/rum20/kp/fairseq-kpg/exps/kp/transformer_presabs_kp20k/outputs/beamsearch-width_50-maxlen_40/pred/checkpoint_step_95000-data_kp20k_valid2k_test.pred',\n",
    "    'bart-o2o': '/zfs1/hdaqing/rum20/kp/fairseq-kpg/exps/kp_o2o/bartFT_one2one_kp20k_100k/outputs/beamsearch-width_128-maxlen_8/pred/checkpoint_step_90000-data_kp20k_valid2k_test.pred',\n",
    "    }\n",
    "\n",
    "pred_results = {}\n",
    "\n",
    "for exp_name, pred_path in pred_paths.items():\n",
    "    pred_results[exp_name] = []\n",
    "    print(exp_name)\n",
    "\n",
    "    with open(pred_path, 'r') as output_json:\n",
    "        for json_line in output_json:\n",
    "            ex_dict = json.loads(json_line)\n",
    "            pred_results[exp_name].append(ex_dict)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "title: A structural approach to reversible computation\n",
      "abstract: Reversibility is a key issue in the interface between computation and physics, and of growing importance as miniaturization progresses towards its physical limits. Most foundational work on reversible computing to date has focussed on simulations of low-level machine models. By contrast, we develop a more structural approach. We show how high-level functional programs can be mapped compositionally (i.e. in a syntax-directed fashion) into a simple kind of automata which are immediately seen to be reversible. The size of the automaton is linear in the size of the functional term. In mathematical terms, we are building a concrete model of functional computation. This construction stems directly from ideas arising in Geometry of Interaction and Linear Logic-but can be understood without any knowledge of these topics. In fact, it serves as an excellent introduction to them. At the same time, an interesting logical delineation between reversible and irreversible forms of computation emerges from our analysis.  \n",
      "GT-keywords [5]\n",
      "\t [0]  reversible computation\n",
      "\t [1]  linear combinatory algebra\n",
      "\t [2]  term-rewriting\n",
      "\t [3]  automata\n",
      "\t [4]  geometry of interaction\n",
      "\n",
      "PRED-keywords [15/61]\n",
      "\t [0]  ['reversible', 'computation']\n",
      "\t [1]  ['functional', 'programming']\n",
      "\t [2]  ['reversible', 'computing']\n",
      "\t [3]  ['compositionality']\n",
      "\t [4]  ['syntax-directed', 'automata']\n",
      "\t [5]  ['geometry', 'of', 'interaction']\n",
      "\t [6]  ['linear', 'logic']\n",
      "\t [7]  ['automata']\n",
      "\t [8]  ['geometry', 'of', 'interactions']\n",
      "\t [9]  ['reversibility']\n",
      "\t [10]  ['geometry', 'ofinteraction']\n",
      "\t [11]  ['syntax-directed', 'computation']\n",
      "\t [12]  ['computation']\n",
      "\t [13]  ['syntax-directed', 'programming']\n",
      "\t [14]  ['symbolic', 'computation']\n"
     ]
    }
   ],
   "source": [
    "dataset_name = 'kp20k_valid2k'\n",
    "exp_name = 'bart-o2s'\n",
    "num_pred = 15\n",
    "\n",
    "data_count = 0\n",
    "for ex_data, pred_data in zip(dataset_examples[dataset_name], pred_results[exp_name]):\n",
    "#     print(ex_data)\n",
    "#     print(pred_data)\n",
    "    data_count += 1\n",
    "    \n",
    "    if data_count < 12:\n",
    "        continue\n",
    "        \n",
    "    print('title:', ex_data['title'])\n",
    "    print('abstract:', ex_data['abstract'])\n",
    "    print('GT-keywords [%d]' % len(ex_data['keywords']))\n",
    "    for gt_id, gt in enumerate(ex_data['keywords']):\n",
    "        print('\\t [%d] ' % gt_id, gt)\n",
    "    \n",
    "    print()\n",
    "    print('PRED-keywords [%d/%d]' % (num_pred, len(pred_sents)))\n",
    "    pred_sents = pred_data['pred_sents']\n",
    "    for pred_id, pred in enumerate(pred_sents[: min(num_pred, len(pred_sents))]):\n",
    "        print('\\t [%d] ' % pred_id, pred)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
