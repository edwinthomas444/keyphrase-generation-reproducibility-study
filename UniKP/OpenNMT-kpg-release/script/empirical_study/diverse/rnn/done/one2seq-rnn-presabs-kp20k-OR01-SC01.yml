exp: rnn-presabs-kp20k-OR01-SC01
exp_dir: /zfs1/pbrusilovsky/rum20/kp/diverse_exps/rnn-presabs-kp20k-OR01-SC01
save_model: /zfs1/pbrusilovsky/rum20/kp/diverse_exps/rnn-presabs-kp20k-OR01-SC01/ckpts/checkpoint
log_file: /zfs1/pbrusilovsky/rum20/kp/diverse_exps/rnn-presabs-kp20k-OR01-SC01/log.txt
wandb_project: kp20k-meng17-presabs

### KP parameters
target_encoder_type: 'rnn'
detach_target_encoder: 'true'
num_negsample: 32
orth_reg: 'true'
lambda_orth_reg: 0.1
sem_cov: 'true'
lambda_sem_cov: 0.1
use_ending_state: 'true'

### Data opts:
model_task: seq2seq
data_type: keyphrase
data_format: jsonl

src_seq_length_trunc: 512
tgt_seq_length_trunc: 128
shuffle_shards: false
data:
    corpus_1:
        path_src: /zfs1/hdaqing/rum20/kp/data/kp/json/kp20k/train.json
        type: keyphrase
        transforms: [keyphrase, onmt_tokenize]

### Transform related opts:
#### Keyphrase specific
kp_concat_type: pres_abs

share_vocab: True
#### Word and vocab
src_vocab: /zfs1/pbrusilovsky/rum20/kp/OpenNMT-kpg/data/keyphrase/meng17/magkp20k.vocab.json
src_vocab_size: 50000
lowercase: True
return_tokens: True
keep_punctuations: True
add_src_boseos: False

# Model opts:
encoder_type: brnn
rnn_type: GRU
decoder_type: rnn
input_feed: 1
word_vec_size: 100
rnn_size: 150
layers: 1
dropout: 0.1

share_embeddings: 'true'
copy_attn: 'true'
reuse_copy_attn: 'true'
coverage_attn: 'false'
context_gate: both
param_init_glorot: 'true'
position_encoding: 'false'
global_attention: mlp

optim: adagrad
learning_rate: 0.05
adagrad_accumulator_init: 0.1
max_grad_norm: 1.0

batch_size: 32
accum_count: 2
valid_batch_size: 64

batch_type: sents
normalization: sents

train_steps: 100000
valid_steps: 1000000
save_checkpoint_steps: 10000
report_every: 100
seed: 3435

log_file_level: DEBUG
tensorboard: 'false'

#tensorboard_log_dir: runs/kp20k.one2one.rnn/

wandb: 'false'
wandb_key: 'c338136c195ab221b8c7cfaa446db16b2e86c6db'


world_size: 1
gpu_ranks:
- 0
#- 1
#- 2
#master_port: 10000